replay_buffer_size: 1000000
rollout_length: 100
learning_starts: 50000
batch_size: 512
model_push_period: 10
target_sync_period: 2500
n_step: 3
train_eps: 0.4
eval_eps: 0.01
priority_exponent: 0.6
importance_sampling_exponent: 0.4
n_tau_samples: 8  # this is a feature for distributional, no need to create a new config

optimizer:
  lr: 0.0000625
  eps: 1e-4